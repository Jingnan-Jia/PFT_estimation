{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjia/.local/lib/python3.8/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.2, the latest is 0.5.3.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n",
      "/home/jjia/.local/lib/python3.8/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package outdated is out of date. Your version is 0.2.1, the latest is 0.2.2.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from skimage.morphology import skeletonize_3d\n",
    "from medutils.medutils import load_itk, save_itk\n",
    "import SimpleITK as sitk\n",
    "import itk\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.morphology import disk,diamond,rectangle,square,erosion,dilation,opening,closing,skeletonize\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'/data1/jjia/lung_function/lung_function/scripts/jupyter_notebooks'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'monai' has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 298\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m, im \u001b[39min\u001b[39;00m id_input_dt\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    297\u001b[0m     args\u001b[39m.\u001b[39minput_mode \u001b[39m=\u001b[39m im\n\u001b[0;32m--> 298\u001b[0m     batch_occlusion(args, \u001b[39mid\u001b[39;49m, max_img_nb\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, occ_status\u001b[39m=\u001b[39;49mocc_status)\n\u001b[1;32m    299\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m---------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    300\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mfinish all!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 250\u001b[0m, in \u001b[0;36mbatch_occlusion\u001b[0;34m(args, net_id, max_img_nb, occ_status)\u001b[0m\n\u001b[1;32m    247\u001b[0m label_all_sorted \u001b[39m=\u001b[39m label_all\u001b[39m.\u001b[39mloc[mae_all[\u001b[39m'\u001b[39m\u001b[39maverage\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39margsort()[:max_img_nb]]\n\u001b[1;32m    248\u001b[0m top_pats \u001b[39m=\u001b[39m label_all_sorted[\u001b[39m'\u001b[39m\u001b[39mpat_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto_list()\n\u001b[0;32m--> 250\u001b[0m data_dt \u001b[39m=\u001b[39m all_loaders(mypath\u001b[39m.\u001b[39;49mdata_dir, mypath\u001b[39m.\u001b[39;49mlabel_fpath,\n\u001b[1;32m    251\u001b[0m                       args,datasetmode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m'\u001b[39;49m, top_pats\u001b[39m=\u001b[39;49mtop_pats)  \u001b[39m# set nb to save time\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39m# only show visualization maps for valid dataset\u001b[39;00m\n\u001b[1;32m    253\u001b[0m valid_dataloader \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(data_dt[mode])\n",
      "File \u001b[0;32m~/data/lung_function/lung_function/modules/datasets.py:346\u001b[0m, in \u001b[0;36mall_loaders\u001b[0;34m(data_dir, label_fpath, args, datasetmode, nb, top_pats, balanced_sampler)\u001b[0m\n\u001b[1;32m    343\u001b[0m     data_dt[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m train_dataloader\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m datasetmode:\n\u001b[0;32m--> 346\u001b[0m     vd_dataset \u001b[39m=\u001b[39m monai\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39mCacheDataset(data\u001b[39m=\u001b[39mvd_data, transform\u001b[39m=\u001b[39mxformd(\n\u001b[1;32m    347\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m, args, pad_truncated_dir\u001b[39m=\u001b[39mpad_truncated_dir), num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, cache_rate\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    348\u001b[0m     valid_dataloader \u001b[39m=\u001b[39m DataLoader(vd_dataset, batch_size\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mbatch_size,\n\u001b[1;32m    349\u001b[0m                                   shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_workers\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mworkers, persistent_workers\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    350\u001b[0m     data_dt[\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m valid_dataloader\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'monai' has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 3/28/21 2:18 PM\n",
    "# @Author  : Jingnan\n",
    "# @Email   : jiajingnan2222@gmail.com\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib import cm\n",
    "from medutils.medutils import load_itk, save_itk\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import morphology\n",
    "from lung_function.modules.compute_metrics import icc, metrics\n",
    "from lung_function.modules.tool import record_1st, record_artifacts, record_cgpu_info, retrive_run\n",
    "from lung_function.modules.set_args import get_args\n",
    "from lung_function.modules.path import PFTPath\n",
    "from lung_function.modules.networks import get_net_3d\n",
    "from lung_function.modules.loss import get_loss\n",
    "from lung_function.modules.datasets import all_loaders\n",
    "from lung_function.modules.trans import batch_bbox2_3D\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "import scipy\n",
    "import itk\n",
    "import os\n",
    "from monai.utils import set_determinism\n",
    "import random\n",
    "import numpy as np\n",
    "from mlflow.tracking import MlflowClient\n",
    "import statistics\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from monai.transforms import ScaleIntensityRange\n",
    "import pandas as pd\n",
    "import torch\n",
    "from queue import Queue\n",
    "from medutils import medutils\n",
    "from medutils.medutils import count_parameters\n",
    "import time\n",
    "import threading\n",
    "import mlflow\n",
    "from mlflow import log_metric, log_metrics, log_param, log_params\n",
    "import sys\n",
    "sys.path.append(\"../../..\")  #\n",
    "print(os.getcwdb())\n",
    "\n",
    "args = get_args(jupyter=True)\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "def masked_filter(method, img, sigma, mask):\n",
    "    \"\"\"\n",
    "    method: 'gaussian' or 'median'\n",
    "    img: image\n",
    "    sigma: int\n",
    "    mask: binary image with the same shape as img\n",
    "    \"\"\"\n",
    "    # normalized convolution of image with mask\n",
    "    if method == 'gaussian':\n",
    "        filter = scipy.ndimage.filters.gaussian_filter(img * mask, sigma = sigma)\n",
    "        weights = scipy.ndimage.filters.gaussian_filter(mask, sigma = sigma)\n",
    "    elif method == 'median':\n",
    "        filter = scipy.ndimage.filters.median_filter(img * mask, size = sigma)\n",
    "        weights = scipy.ndimage.filters.median_filter(mask, size = sigma)\n",
    "    else:\n",
    "        raise Exception(f\"filter method: {method}, but it should be 'gaussian' or 'median\")\n",
    "    filter /= weights\n",
    "    # after normalized convolution, you can choose to delete any data outside the mask:\n",
    "    filter *= mask\n",
    "    return filter\n",
    "\n",
    "def marphology(input_fpath, method, output_fpath, radius=2):\n",
    "\n",
    "    PixelType = itk.F\n",
    "    Dimension = 3\n",
    "\n",
    "    ImageType = itk.Image[PixelType, Dimension]\n",
    "    ReaderType = itk.ImageFileReader[ImageType]\n",
    "    reader = ReaderType.New()\n",
    "    reader.SetFileName(input_fpath)\n",
    "\n",
    "    StructuringElementType = itk.FlatStructuringElement[Dimension]\n",
    "    structuringElement = StructuringElementType.Ball(radius)\n",
    "    if 'dilate' == method:\n",
    "        GrayscaleFilterType = itk.GrayscaleDilateImageFilter[\n",
    "            ImageType, ImageType, StructuringElementType\n",
    "        ]\n",
    "    elif 'erode' == method:\n",
    "        GrayscaleFilterType = itk.GrayscaleErodeImageFilter[\n",
    "            ImageType, ImageType, StructuringElementType\n",
    "        ]\n",
    "    else:\n",
    "        raise Exception(f'wrong method {method}')\n",
    "    grayscaleFilter = GrayscaleFilterType.New()\n",
    "    grayscaleFilter.SetInput(reader.GetOutput())\n",
    "    grayscaleFilter.SetKernel(structuringElement)\n",
    "\n",
    "    WriterType = itk.ImageFileWriter[ImageType]\n",
    "    writer = WriterType.New()\n",
    "    writer.SetFileName(output_fpath)\n",
    "    writer.SetInput(grayscaleFilter.GetOutput())\n",
    "\n",
    "    writer.Update()\n",
    "\n",
    "    out = load_itk(output_fpath)\n",
    "\n",
    "    out = out/1500\n",
    "   \n",
    "    return out \n",
    "\n",
    "def occlusion_map(data, net,  targets=None, occlusion_dir=None, save_occ_x=False, occ_status='healthy', inputmode='ct'):\n",
    "    \"\"\"Save occlusion map to disk.\n",
    "\n",
    "    Args:\n",
    "        ptch: patch side lenth\n",
    "        x: image to be predicted, shape [channel, w, h]\n",
    "        y: predicted scores, shape [1, 3]\n",
    "        net: network\n",
    "        lung_mask: lung mask to ensure the occlusion occurs in lung area, shape [channel, w, h]\n",
    "        occlusion_dir: directory to save occlusion maps\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.isdir(occlusion_dir):\n",
    "        os.makedirs(occlusion_dir)\n",
    "    batch_x, y, lung_mask, ori, sp = data[inputmode][0], data['label'][0], data['lung_mask'][0], data['origin'][0], data['spacing'][0]\n",
    "    input_mode = inputmode\n",
    "    if input_mode == 'ct_masked_by_lung':\n",
    "        a = copy.deepcopy(lung_mask)  # shape of batch_x and lung mask: [channel, z,y,x]\n",
    "        a[a > 0] = 1\n",
    "        batch_x += 1  # shift lowest value from -1 to 0\n",
    "        batch_x = batch_x * a\n",
    "        batch_x -= 1\n",
    "    elif input_mode == 'ct_masked_by_left_lung':\n",
    "        a = copy.deepcopy(lung_mask)\n",
    "        a[a !=2] = 0\n",
    "        batch_x += 1  # shift lowest value from -1 to 0\n",
    "        batch_x = batch_x * a\n",
    "        batch_x -= 1\n",
    "    elif input_mode == 'ct_masked_by_right_lung':\n",
    "        a = copy.deepcopy(lung_mask)\n",
    "        a[a !=1] = 0\n",
    "        batch_x += 1  # shift lowest value from -1 to 0\n",
    "        batch_x = batch_x * a\n",
    "        batch_x -= 1\n",
    "    elif input_mode in ('ct_left', 'ct_right', 'ct_upper', 'ct_lower', 'ct_front', 'ct_back'):\n",
    "        lung_mask = copy.deepcopy(lung_mask)\n",
    "        lung_mask[lung_mask > 0] = 1\n",
    "        if 'in_lung' in input_mode:  # only keep values in lung\n",
    "            batch_x += 1  # shift lowest value from -1 to 0\n",
    "            batch_x = batch_x * lung_mask  # masked by lung\n",
    "            batch_x -= 1\n",
    "\n",
    "        z_bottom, z_top, y_bottom, y_top, x_bottom, x_top = batch_bbox2_3D(lung_mask)\n",
    "        z_mid, y_mid, x_mid = (z_bottom + z_top)//2, (y_bottom + y_top)//2, (x_bottom + x_top)//2\n",
    "        # for idx in range(batch_x.shape[0]):\n",
    "        if input_mode == 'ct_upper':\n",
    "            batch_x[:, :z_mid[idx], :, :] = - 1  # remove bottom\n",
    "        elif input_mode == 'ct_lower':\n",
    "            batch_x[:, z_mid[idx]:, :, :] = - 1  # remove upper\n",
    "        elif input_mode == 'ct_back':\n",
    "            batch_x[:, :, y_mid[idx]:, :] = - 1  # remove front, keep back\n",
    "        elif input_mode == 'ct_front':\n",
    "            batch_x[:, :, :y_mid[idx], :] = - 1  # remove back, keep front\n",
    "        elif input_mode == 'ct_left':\n",
    "            batch_x[:, :, :, :x_mid[idx]] = - 1  # remove right\n",
    "        else:  # args.input_mode == 'ct_front':\n",
    "            batch_x[:, :, :, x_mid[idx]:] = - 1  # remove left\n",
    "    else:\n",
    "        pass\n",
    "    x = batch_x[0]  # shape: x,y,z\n",
    "    \n",
    "    # lung_mask = morphology.binary_erosion(lung_mask.numpy(), np.ones((6, 6))).astype(int)\n",
    "    x = x.to(device)  # shape [channel, w, h]\n",
    "    net.to(device)\n",
    "    x_ = x.unsqueeze(0).unsqueeze(0)  # add a channel and batch dims\n",
    "    out_ori = net(x_)\n",
    "\n",
    "\n",
    "    # Three-pattern scores\n",
    "    out_ori = out_ori.detach().cpu().numpy().flatten()\n",
    "\n",
    "    x_np = x.clone().detach().cpu().numpy()  # shape [l, w, h]\n",
    "\n",
    "    pred_str = \"\"\n",
    "    for t, p in zip(targets, out_ori):\n",
    "        pred_str += f\"{t}_{p:.2f}_\"\n",
    "    fpath_occ_x = f\"{occlusion_dir}/no_occlusion_pred_{pred_str}.mha\"\n",
    "    save_itk(fpath_occ_x, x_np*1500, ori.tolist(), sp.tolist(), dtype='float')\n",
    "\n",
    "    x_np_dilasion = marphology(fpath_occ_x, 'dilate', output_fpath=f\"{occlusion_dir}/global_dilated.mha\")\n",
    "    x_dilated = torch.tensor(x_np_dilasion).float()\n",
    "    x_dilated = x_dilated.unsqueeze(0).unsqueeze(0)\n",
    "    x_dilated = x_dilated.to(device)\n",
    "    out_dilated = net(x_dilated)\n",
    "    out_np_dilated = out_dilated.clone().detach().cpu().numpy().flatten()\n",
    "\n",
    "    x_np_erosion = marphology(fpath_occ_x, 'erode', output_fpath=f\"{occlusion_dir}/global_eroded.mha\")\n",
    "    x_eroded = torch.tensor(x_np_erosion).float()\n",
    "    x_eroded = x_eroded.unsqueeze(0).unsqueeze(0)\n",
    "    x_eroded = x_eroded.to(device)\n",
    "    out_eroded = net(x_eroded)\n",
    "    out_np_eroded = out_eroded.clone().detach().cpu().numpy().flatten()\n",
    "\n",
    "    y_ls = list(y.numpy().flatten())\n",
    "    pred_ls = list(out_ori)\n",
    "    pred_dilated_ls = list(out_np_dilated)\n",
    "    pred_eroded_ls = list(out_np_eroded)\n",
    "\n",
    "    # per label\n",
    "    for target, score, pred, pred_di, pred_er in zip(targets, y_ls, pred_ls, pred_dilated_ls, pred_eroded_ls):\n",
    "        fpath = f\"{occlusion_dir}/{target}_label_{score: .2f}_predOri_{pred: .2f}_predDilated_{pred_di: .2f}_predEroded_{pred_er: .2f}.mha\"\n",
    "        save_itk(fpath, x, ori.tolist(), sp.tolist(), dtype='float')\n",
    "\n",
    "\n",
    "\n",
    "def batch_occlusion(args, net_id: int, max_img_nb: int, occ_status='healthy'):\n",
    "    \"\"\"Generate a batch of occlusion results\n",
    "\n",
    "    Args:\n",
    "        net_id (int): _description_\n",
    "        patch_size (int): _description_\n",
    "        stride (int): _description_\n",
    "        max_img_nb (int): _description_\n",
    "        occ_status (str, optional): _description_. Defaults to 'healthy'.\n",
    "    \"\"\"\n",
    "\n",
    "    targets = [i.lstrip() for i in args.target.split('-')\n",
    "               ]  # FVC-DLCO_SB-FEV1-TLC_He\n",
    "    net = get_net_3d(name=args.net, nb_cls=len(\n",
    "        targets), image_size=args.x_size, pretrained=False)  # output FVC and FEV1\n",
    "\n",
    "    mypath = PFTPath(net_id, space=args.ct_sp)  # get path\n",
    "    mode = 'valid'\n",
    "    label_all = pd.read_csv(mypath.save_label_fpath(mode))\n",
    "    pred_all = pd.read_csv(mypath.save_pred_fpath(mode))\n",
    "    mae_all = (label_all - pred_all).abs()\n",
    "    mae_all['average'] = mae_all.mean(numeric_only=True, axis=1)\n",
    "    label_all_sorted = label_all.loc[mae_all['average'].argsort()[:max_img_nb]]\n",
    "    top_pats = label_all_sorted['pat_id'].to_list()\n",
    "\n",
    "    data_dt = all_loaders(mypath.data_dir, mypath.label_fpath,\n",
    "                          args,datasetmode='valid', top_pats=top_pats)  # set nb to save time\n",
    "    # only show visualization maps for valid dataset\n",
    "    valid_dataloader = iter(data_dt[mode])\n",
    "\n",
    "    ckpt = torch.load(mypath.model_fpath, map_location=device)\n",
    "    if type(ckpt) is dict and 'model' in ckpt:\n",
    "        model = ckpt['model']\n",
    "    else:\n",
    "        model = ckpt\n",
    "    net.load_state_dict(model, strict=False)  # load trained weights\n",
    "    net.eval()  # 8\n",
    "\n",
    "    for data in tqdm(valid_dataloader):  # a image in a batch\n",
    "        if int(data['pat_id']) in top_pats:  # only perform the most accurate patients\n",
    "            occlusion_map_dir = f\"{mypath.id_dir}/{'valid_data_global_' + occ_status}/SSc_{data['pat_id'][0][0]}\"\n",
    "            occlusion_map(data,\n",
    "                          net,\n",
    "                          targets,\n",
    "                          occlusion_map_dir,\n",
    "                          save_occ_x=True,\n",
    "                          occ_status=occ_status,\n",
    "                          inputmode=args.input_mode)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # for occ_status in ['shuffle', 'blur_median_5', 'blur_gaussian_5']:\n",
    "    occ_status = 'dilasion'  # 'erosion', 'constant' or 'healthy', or 'blur_median_*', or 'blur_gaussian_*', -1 is the minimum value\n",
    "\n",
    "    # 2414->2415_fold1: ct_masked_by_torso\n",
    "    # 2194->2195_fold1: ct\n",
    "    # 2144->2145_fold1: ct_masked_by_lung\n",
    "    # 2258->2259_fold1: vessel\n",
    "\n",
    "\n",
    "    args = get_args(jupyter=True)  # get argument\n",
    "    args.batch_size = 1  # here batch size must be 1.\n",
    "    args.net = 'vgg11_3d'\n",
    "    args.target = 'FVC-DLCO_SB-FEV1-TLC_He'\n",
    "    args.ct_sp = '1.5'\n",
    "\n",
    "    id_input_dt = {\n",
    "            2415: 'ct_masked_by_torso', \n",
    "            2195: 'ct', \n",
    "            2145: 'ct_masked_by_lung', \n",
    "            2259: 'vessel' }\n",
    "    for id, im in id_input_dt.items():\n",
    "        args.input_mode = im\n",
    "        batch_occlusion(args, id, max_img_nb=1, occ_status=occ_status)\n",
    "        print('---------------')\n",
    "    print('finish all!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7237c9972df760705e03bb27a8e106ab1bc3793b010c014a347ab079be8db1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
