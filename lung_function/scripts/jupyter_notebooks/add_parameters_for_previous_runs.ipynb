{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjia/.local/lib/python3.8/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.2, the latest is 0.5.3.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n",
      "/home/jjia/.local/lib/python3.8/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package outdated is out of date. Your version is 0.2.1, the latest is 0.2.2.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from lung_function.modules.compute_metrics import icc, metrics\n",
    "from mlflow import log_params\n",
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for new experiments\n",
    "b_ls = []\n",
    "b_ls.append({0:2521, 1:2522, 2:2531, 3:2544, 4:2545, 'name':''})\n",
    "b_ls.append({0:2527, 1:2528, 2:2546, 3:2556, 4:2566, 'name':''})\n",
    "b_ls.append({0:2529, 1:2530, 2:2547, 3:2557, 4:2567, 'name':''})\n",
    "b_ls.append({0:2532, 1:2533, 2:2548, 3:2558, 4:2579, 'name':''})\n",
    "\n",
    "b_ls.append({0:2534, 1:2535, 2:2553, 3:2563, 4:2588, 'name':''})\n",
    "b_ls.append({0:2536, 1:2537, 2:2552, 3:2562, 4:2587, 'name':''})\n",
    "b_ls.append({0:2538, 1:2539, 2:2551, 3:2561, 4:2586, 'name':''})\n",
    "b_ls.append({0:2540, 1:2541, 2:2549, 3:2559, 4:2578, 'name':''})\n",
    "\n",
    "b_ls.append({0:2542, 1:2543, 2:2550, 3:2560, 4:2581, 'name':''})\n",
    "b_ls.append({0:2568, 1:2569, 2:2580, 3:2590, 4:2599, 'name':''})\n",
    "b_ls.append({0:2570, 1:2571, 2:2582, 3:2589, 4:2597, 'name':''})\n",
    "b_ls.append({0:2572, 1:2573, 2:2583, 3:2592, 4:2598, 'name':''})\n",
    "\n",
    "b_ls.append({0:2574, 1:2575, 2:2585, 3:2593, 4:2602, 'name':''})\n",
    "b_ls.append({0:2576, 1:2577, 2:2584, 3:2591, 4:2596, 'name':''})\n",
    "b_ls.append({0:2594, 1:2595, 2:2604, 3:2612, 4:2616, 'name':''})\n",
    "b_ls.append({0:2600, 1:2601, 2:2603, 3:2609, 4:2613, 'name':''})\n",
    "\n",
    "b_ls.append({0:2605, 1:2606, 2:2610, 3:2614, 4:2617, 'name':''})\n",
    "b_ls.append({0:2607, 1:2608, 2:2611, 3:2615, 4:2618, 'name':''})\n",
    "\n",
    "b_ls.append({0:902, 1:903, 2:915, 3:921, 4:926, 'name':''})\n",
    "b_ls.append({0:904, 1:905, 2:914, 3:919, 4:924, 'name':''})\n",
    "b_ls.append({0:906, 1:907, 2:918, 3:925, 4:930, 'name':''})\n",
    "b_ls.append({0:908, 1:909, 2:916, 3:923, 4:929, 'name':''})\n",
    "b_ls.append({0:910, 1:911, 2:920, 3:927, 4:931, 'name':''})\n",
    "b_ls.append({0:912, 1:913, 2:917, 3:922, 4:928, 'name':''})\n",
    "\n",
    "b_ls.append({0:2258, 1:2259, 2:2269, 3:2271, 4:2272, 'name':''})\n",
    "b_ls.append({0:2140, 1:2141, 2:2162, 3:2175, 4:2191, 'name':''})\n",
    "b_ls.append({0:2138, 1:2139, 2:2160, 3:2173, 4:2190, 'name':''})\n",
    "b_ls.append({0:2148, 1:2149, 2:2159, 3:2172, 4:2189, 'name':''})\n",
    "b_ls.append({0:2144, 1:2145, 2:2158, 3:2171, 4:2185, 'name':''})\n",
    "b_ls.append({0:2142, 1:2143, 2:2154, 3:2167, 4:2180, 'name':''})\n",
    "\n",
    "b_ls.append({0:2194, 1:2195, 2:2249, 3:2262, 4:2270, 'name':''})\n",
    "# b_ls.append({0:429, 1:430, 2:432, 3:434, 4:436, 'name':''})\n",
    "\n",
    "b_ls.append({0:2667, 1:2668, 2:2679, 3:2690, 4:2701, 'name':''})\n",
    "b_ls.append({0:2665, 1:2666, 2:2677, 3:2688, 4:2699, 'name':''})\n",
    "b_ls.append({0:2663, 1:2664, 2:2678, 3:2689, 4:2700, 'name':''})\n",
    "b_ls.append({0:2661, 1:2662, 2:2676, 3:2687, 4:2698, 'name':''})\n",
    "b_ls.append({0:2655, 1:2658, 2:2675, 3:2686, 4:2697, 'name':''})\n",
    "b_ls.append({0:2654, 1:2657, 2:2674, 3:2685, 4:2696, 'name':''})\n",
    "b_ls.append({0:2651, 1:2652, 2:2672, 3:2683, 4:2691, 'name':''})\n",
    "b_ls.append({0:2649, 1:2650, 2:2670, 3:2682, 4:2693, 'name':''})\n",
    "b_ls.append({0:2647, 1:2648, 2:2669, 3:2680, 4:2692, 'name':''})\n",
    "b_ls.append({0:2645, 1:2646, 2:2673, 3:2684, 4:2695, 'name':''})\n",
    "b_ls.append({0:2643, 1:2644, 2:2671, 3:2681, 4:2694, 'name':''})\n",
    "\n",
    "\n",
    "b_ls = [{0:2731, 1:2733, 2:2734, 3:2737, 4:2739, 'name':''}]\n",
    "b_ls.append({0:2730, 1:2732, 2:2735, 3:2736, 4:2738, 'name':''})\n",
    "b_ls.append({0:2714, 1:2715, 2:2717, 3:2722, 4:2725, 'name':''})\n",
    "b_ls.append({0:2712, 1:2713, 2:2718, 3:2723, 4:2727, 'name':''})\n",
    "b_ls.append({0:2710, 1:2711, 2:2716, 3:2719, 4:2724, 'name':''})\n",
    "\n",
    "fold_ex_dt_ls = b_ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merging 4 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_4folds_testing(fold_ex_dt_ls):\n",
    "    parent_dir = '/home/jjia/data/lung_function/lung_function/scripts/results/experiments/'\n",
    "\n",
    "    for fold_ex_dt in fold_ex_dt_ls:\n",
    "        dir0 = parent_dir + str(fold_ex_dt[0])\n",
    "        label_fpath = dir0  + '/test_label.csv'\n",
    "        ave_fpath =dir0  + '/test_pred.csv'\n",
    "        output_file_path = Path(ave_fpath)\n",
    "        output_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        df_ls = []\n",
    "        for i in [1,2,3,4]:\n",
    "            data_fpath = parent_dir + str(fold_ex_dt[i]) + '/test_pred.csv'\n",
    "            df = pd.read_csv(data_fpath,index_col=0)\n",
    "            df_ls.append(df)\n",
    "        df_ave = (df_ls[0] + df_ls[1] + df_ls[2] + df_ls[3])/4\n",
    "        df_ave.to_csv(ave_fpath)\n",
    "        \n",
    "        label_fpath_fold1 = parent_dir + str(fold_ex_dt[i]) + '/test_label.csv'\n",
    "        df_label = pd.read_csv(label_fpath_fold1,index_col=0)\n",
    "        df_label.to_csv(label_fpath)\n",
    "        \n",
    "        print(ave_fpath)\n",
    "\n",
    "def ensemble_4folds_validation(fold_ex_dt_ls):\n",
    "    parent_dir = '/home/jjia/data/lung_function/lung_function/scripts/results/experiments/'\n",
    "\n",
    "    for fold_ex_dt in fold_ex_dt_ls:\n",
    "        dir0 = parent_dir + str(fold_ex_dt[0])\n",
    "        pred_all_fpath = dir0  + '/valid_pred.csv'\n",
    "        label_all_fpath = dir0  + '/valid_label.csv'\n",
    "        output_file_path = Path(pred_all_fpath)\n",
    "        output_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        df_pred_ls, df_label_ls = [], []\n",
    "        for i in [1,2,3,4]:\n",
    "            data_fpath = parent_dir + str(fold_ex_dt[i]) + '/valid_pred.csv'\n",
    "            label_fpath = parent_dir + str(fold_ex_dt[i]) + '/valid_label.csv'\n",
    "            df_pred = pd.read_csv(data_fpath,index_col=0)\n",
    "            df_label = pd.read_csv(label_fpath,index_col=0)\n",
    "\n",
    "            df_pred_ls.append(df_pred)\n",
    "            df_label_ls.append(df_label)\n",
    "        df_pred_valid = pd.concat(df_pred_ls)\n",
    "        df_label_valid = pd.concat(df_label_ls)\n",
    "        \n",
    "        df_pred_valid.to_csv(pred_all_fpath)\n",
    "        df_label_valid.to_csv(label_all_fpath)\n",
    "        print(pred_all_fpath)\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jjia/data/lung_function/lung_function/scripts/results/experiments/2731/test_pred.csv\n",
      "/home/jjia/data/lung_function/lung_function/scripts/results/experiments/2730/test_pred.csv\n",
      "/home/jjia/data/lung_function/lung_function/scripts/results/experiments/2714/test_pred.csv\n",
      "/home/jjia/data/lung_function/lung_function/scripts/results/experiments/2712/test_pred.csv\n",
      "/home/jjia/data/lung_function/lung_function/scripts/results/experiments/2710/test_pred.csv\n",
      "/home/jjia/data/lung_function/lung_function/scripts/results/experiments/2731/valid_pred.csv\n",
      "/home/jjia/data/lung_function/lung_function/scripts/results/experiments/2730/valid_pred.csv\n",
      "/home/jjia/data/lung_function/lung_function/scripts/results/experiments/2714/valid_pred.csv\n",
      "/home/jjia/data/lung_function/lung_function/scripts/results/experiments/2712/valid_pred.csv\n",
      "/home/jjia/data/lung_function/lung_function/scripts/results/experiments/2710/valid_pred.csv\n"
     ]
    }
   ],
   "source": [
    "ensemble_4folds_testing(fold_ex_dt_ls)\n",
    "ensemble_4folds_validation(fold_ex_dt_ls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(pred_fpath, label_fpath, ignore_1st_column=True):\n",
    "    mae_dict = {}\n",
    "\n",
    "    label = pd.read_csv(label_fpath)\n",
    "    pred = pd.read_csv(pred_fpath)\n",
    "    if ignore_1st_column:\n",
    "        pred = pred.iloc[: , 1:]\n",
    "        label = label.iloc[: , 1:]\n",
    "    if 'ID' == label.columns[0]:\n",
    "        del label[\"ID\"]\n",
    "    if 'ID' == pred.columns[0]:\n",
    "        del pred[\"ID\"]\n",
    "\n",
    "    original_columns = label.columns\n",
    "\n",
    "    # ori_columns = list(label.columns)\n",
    "\n",
    "    for column in original_columns:\n",
    "        mae_value = (pred[column] - label[column]).abs().mean()\n",
    "        \n",
    "        prefix = label_fpath.split(\"/\")[-1].split(\"_\")[0]\n",
    "        mae_dict['mae_' + prefix + '_' + column] = mae_value\n",
    "    return mae_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2731, 1: 2733, 2: 2734, 3: 2737, 4: 2739, 'name': ''}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Either missing values are present in data or data are unbalanced. Please remove them manually or use nan_policy='omit'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m pred_fpath \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mparent_dir\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mi[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m_pred.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[39m# add icc\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m icc_value \u001b[39m=\u001b[39m icc(label_fpath, pred_fpath, ignore_1st_column\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     23\u001b[0m icc_value_ensemble \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mensemble_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m k:v  \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m icc_value\u001b[39m.\u001b[39mitems()}  \u001b[39m# update keys\u001b[39;00m\n\u001b[1;32m     24\u001b[0m log_params(icc_value_ensemble)\n",
      "File \u001b[0;32m~/data/lung_function/lung_function/modules/compute_metrics.py:62\u001b[0m, in \u001b[0;36micc\u001b[0;34m(label_fpath, pred_fpath, ignore_1st_column)\u001b[0m\n\u001b[1;32m     59\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([label, pred], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m original_columns:\n\u001b[0;32m---> 62\u001b[0m     icc \u001b[39m=\u001b[39m pg\u001b[39m.\u001b[39;49mintraclass_corr(data\u001b[39m=\u001b[39;49mdata, targets\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mID\u001b[39;49m\u001b[39m'\u001b[39;49m, raters\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrater\u001b[39;49m\u001b[39m'\u001b[39;49m, ratings\u001b[39m=\u001b[39;49mcolumn)\u001b[39m.\u001b[39mround(\u001b[39m2\u001b[39m)\n\u001b[1;32m     63\u001b[0m     icc \u001b[39m=\u001b[39m icc\u001b[39m.\u001b[39mset_index(\u001b[39m\"\u001b[39m\u001b[39mType\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m     icc \u001b[39m=\u001b[39m icc\u001b[39m.\u001b[39mloc[\u001b[39m'\u001b[39m\u001b[39mICC2\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mICC\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pingouin/reliability.py:276\u001b[0m, in \u001b[0;36mintraclass_corr\u001b[0;34m(data, targets, raters, ratings, nan_policy)\u001b[0m\n\u001b[1;32m    274\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mdropna(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39many\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    275\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mEither missing values are present in data or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mdata are unbalanced. Please remove them \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmanually or use nan_policy=\u001b[39m\u001b[39m'\u001b[39m\u001b[39momit\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         )\n\u001b[1;32m    282\u001b[0m \u001b[39m# Back to long-format\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39m# data_wide = data.copy()  # Optional, for PCA\u001b[39;00m\n\u001b[1;32m    284\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mreset_index()\u001b[39m.\u001b[39mmelt(id_vars\u001b[39m=\u001b[39mtargets, value_name\u001b[39m=\u001b[39mratings)\n",
      "\u001b[0;31mValueError\u001b[0m: Either missing values are present in data or data are unbalanced. Please remove them manually or use nan_policy='omit'."
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://nodelogin02:5000\")\n",
    "experiment = mlflow.set_experiment(\"lung_fun_db15\")\n",
    "\n",
    "# Create a run under the default experiment (whose id is '0').\n",
    "client = mlflow.MlflowClient()\n",
    "parent_dir = '/home/jjia/data/lung_function/lung_function/scripts/results/experiments/'\n",
    "\n",
    "for i in fold_ex_dt_ls:\n",
    "    print(i)\n",
    "    experiment_id = i[0]\n",
    "    run_ls = client.search_runs(experiment_ids=[experiment.experiment_id], run_view_type=1, filter_string=f\"params.id LIKE '%{experiment_id}%'\")\n",
    "    if len(run_ls)!=0:\n",
    "        run_ = run_ls[-1]\n",
    "        run_id = run_.info.run_id\n",
    "        \n",
    "        with mlflow.start_run(run_id=run_id):\n",
    "            for mode in ['valid', 'test']:\n",
    "                label_fpath = f\"{parent_dir}{i[1]}/{mode}_label.csv\"\n",
    "                pred_fpath = f\"{parent_dir}{i[0]}/{mode}_pred.csv\"\n",
    "\n",
    "                # add icc\n",
    "                icc_value = icc(label_fpath, pred_fpath, ignore_1st_column=True)\n",
    "                icc_value_ensemble = {'ensemble_' + k:v  for k, v in icc_value.items()}  # update keys\n",
    "                log_params(icc_value_ensemble)\n",
    "\n",
    "                # add r\n",
    "                r_p_value = metrics(pred_fpath, label_fpath, ignore_1st_column=True)\n",
    "                r_p_value_ensemble = {'ensemble_' + k:v  for k, v in r_p_value.items()}  # update keys\n",
    "                log_params(r_p_value_ensemble)\n",
    "                \n",
    "                # add mae\n",
    "                mae_dict = mae(pred_fpath, label_fpath, ignore_1st_column=True)\n",
    "                mae_ensemble = {'ensemble_' + k:v for k, v in mae_dict.items()}\n",
    "                log_params(mae_ensemble)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7237c9972df760705e03bb27a8e106ab1bc3793b010c014a347ab079be8db1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
