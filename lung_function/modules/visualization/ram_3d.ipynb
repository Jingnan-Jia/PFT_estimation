{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This aims to generate 3D Grad-CAM for regression networks, or, RAM_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The package outdated is out of date. Your version is 0.2.1, the latest is 0.2.2.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "The package pingouin is out of date. Your version is 0.5.2, the latest is 0.5.3.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [--net {vgg11_3d,vit3,vgg16_3d,vgg19_3d,r3d_resnet,cnn3fc1,cnn4fc2,cnn5fc2,cnn6fc2,cnn2fc1,cnn3fc2,r3d_18,slow_r50,slowfast_r50,x3d_xs,x3d_s,x3d_m,x3d_l,pointnet_reg,pointnet2_reg,vgg11_3d,pointnext}]\n",
      "                             [--cfg CFG] [--fc2_nodes FC2_NODES]\n",
      "                             [--fc1_nodes FC1_NODES]\n",
      "                             [--pointnet_fc_ls POINTNET_FC_LS]\n",
      "                             [--dp_fc1_flag DP_FC1_FLAG]\n",
      "                             [--npoint_base NPOINT_BASE]\n",
      "                             [--radius_base RADIUS_BASE]\n",
      "                             [--nsample_base NSAMPLE_BASE] [--width WIDTH]\n",
      "                             [--radius_scaling RADIUS_SCALING]\n",
      "                             [--sa_layers SA_LAYERS] [--batch_size BATCH_SIZE]\n",
      "                             [--ct_sp {ori,1.0,1.5}] [--kfold_seed KFOLD_SEED]\n",
      "                             [--test_pat {zhiwei77,random,random_as_ori}]\n",
      "                             [--input_mode {ct,ct_masked_by_torso,ct_left,ct_masked_by_lung,ct_masked_by_left_lung,ct_masked_by_right_lung,ct_right,ct_left_in_lung,ct_right_in_lung,ct_upper,ct_lower,ct_front,ct_back,ct_upper_in_lung,ct_lower_in_lung,ct_front_in_lung,ct_back_in_lung,vessel,ct_masked_by_vessel,vessel_skeleton_pcd,ct_masked_by_vessel_dilated1,ct_masked_by_vessel_dilated2,ct_masked_by_vessel_dilated3,ct_masked_by_vessel_dilated4,IntrA_cls}]\n",
      "                             [--target TARGET] [--workers WORKERS]\n",
      "                             [--balanced_sampler BALANCED_SAMPLER]\n",
      "                             [--crop_foreground CROP_FOREGROUND]\n",
      "                             [--z_size Z_SIZE] [--y_size Y_SIZE]\n",
      "                             [--x_size X_SIZE] [--pad_ratio PAD_RATIO]\n",
      "                             [--shift_range SHIFT_RANGE] [--PNB PNB]\n",
      "                             [--FPS_input FPS_INPUT]\n",
      "                             [--repeated_sample REPEATED_SAMPLE]\n",
      "                             [--position_center_norm POSITION_CENTER_NORM]\n",
      "                             [--mode {train,infer,continue_train}]\n",
      "                             [--pretrained_id PRETRAINED_ID]\n",
      "                             [--pretrained_imgnet PRETRAINED_IMGNET]\n",
      "                             [--total_folds {4,5}] [--fold {1,2,3,4}]\n",
      "                             [--valid_period VALID_PERIOD]\n",
      "                             [--loss {mse,mae,smooth_mae,mse+mae,msehigher,mse_regular}]\n",
      "                             [--mat_diff_loss_scale MAT_DIFF_LOSS_SCALE]\n",
      "                             [--epochs EPOCHS] [--weight_decay WEIGHT_DECAY]\n",
      "                             [--lr LR] [--adamw ADAMW]\n",
      "                             [--cosine_decay COSINE_DECAY] [--outfile OUTFILE]\n",
      "                             [--hostname HOSTNAME] [--remark REMARK]\n",
      "                             [--jobid JOBID]\n",
      "ipykernel_launcher.py: error: ambiguous option: --f=/home/jjia/.local/share/jupyter/runtime/kernel-v2-4230707C2hHXuETOC3.json could match --fc2_nodes, --fc1_nodes, --fold\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# sys.path.append(\"../..\")\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pytorch_grad_cam import GradCAMPlusPlus\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from tqdm import tqdm\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from mlflow import log_metric, log_metrics, log_param, log_params\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from medcam3d import GradCAM\n",
    "\n",
    "from lung_function.modules.path import PFTPath\n",
    "from lung_function.modules.datasets import all_loaders\n",
    "# from lung_function.modules.cam import GradCAM\n",
    "from lung_function.scripts.run import Run\n",
    "from lung_function.modules.set_args import get_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:  # convert dict to class attribute\n",
    "    def __init__(self, d=None):\n",
    "        if d is not None:\n",
    "            for key, value in d.items():\n",
    "                if value == 'True':\n",
    "                    value = True\n",
    "                elif value == 'False':\n",
    "                    value = False\n",
    "                else:\n",
    "                    try:\n",
    "                        value = float(value)  # convert to float value if possible\n",
    "                        try:\n",
    "                            if int(value) == value:  # convert to int if possible\n",
    "                                value = int(value)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                setattr(self, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionOutputTarget:  # devine my custom target\n",
    "    def __init__(self, name):\n",
    "        self.name = name  # possible names: DLCOc, FEV1, FVC, TLC, DLCOcPP, FEV1PP, FVCPP, TLCPP\n",
    "\n",
    "    def __call__(self, model_output):\n",
    "        if len(model_output.shape) == 1:  # shape: (N,), A vector\n",
    "            if model_output.shape[0] == 1:\n",
    "                return model_output  # TODO: for the single output network\n",
    "            return model_output[self.category]  # return one node\n",
    "        \n",
    "        # shape: (M, N), A 2d array\n",
    "        return model_output[:, self.category]  # return a vector \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update parameters\n",
    "AttentionMethod = \"GradCAM\"  # or others\n",
    "Ex_id = 2656  # FVC, fold1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# retrive the run for the ex id\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mlflow\u001b[39m.\u001b[39mset_tracking_uri(\u001b[39m\"\u001b[39m\u001b[39mhttp://nodelogin02:5000\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m experiment \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39mset_experiment(\u001b[39m\"\u001b[39m\u001b[39mlung_fun_db15\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m client \u001b[39m=\u001b[39m MlflowClient()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlflow' is not defined"
     ]
    }
   ],
   "source": [
    "# retrive the run for the ex id\n",
    "mlflow.set_tracking_uri(\"http://nodelogin02:5000\")\n",
    "experiment = mlflow.set_experiment(\"lung_fun_db15\")\n",
    "client = MlflowClient()\n",
    "run_ls = client.search_runs(experiment_ids=[experiment.experiment_id],\n",
    "                            filter_string=f\"params.id LIKE '%{Ex_id}%'\")\n",
    "run_ = run_ls[0]\n",
    "args_dt = run_.data.params  # extract the hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "args = Args(args_dt)  #convert to object\n",
    "args.workers=1\n",
    "\n",
    "args.use_cuda = True\n",
    "device = torch.device(\"cuda:0\" if args.use_cuda else \"cpu\")\n",
    "\n",
    "    \n",
    "ckpt = torch.load(self.mypath.model_fpath, map_location=device)\n",
    "if type(ckpt) is dict and 'model' in ckpt:\n",
    "    model = ckpt['model']\n",
    "else:\n",
    "    model = ckpt\n",
    "self.net.load_state_dict(model)  # model_fpath need to exist\n",
    "\n",
    "target_layers = [self.net.layer4[-1]]  # TODO: change this line select which layer\n",
    "targets = [RegressionOutputTarget(args.target)]  # TODO: change it to select which output\n",
    "if AttentionMethod==\"GradCAM\":\n",
    "    cam = GradCAM(model=self.net, target_layers=target_layers, use_cuda=args.use_cuda)\n",
    "    # attention = GradCAM(Ex_id, args_dt, 'last_maxpool')\n",
    "else:\n",
    "    raise Exception(f\"Please set the correct AttentionMethod\")\n",
    "\n",
    "\n",
    "\n",
    "mypath = PFTPath(Ex_id, check_id_dir=False, space=args.ct_sp)\n",
    "\n",
    "# select the top accurate patients\n",
    "mode = 'valid'\n",
    "label_all = pd.read_csv(mypath.save_label_fpath(mode))\n",
    "pred_all = pd.read_csv(mypath.save_pred_fpath(mode))\n",
    "mae_all = (label_all - pred_all).abs()\n",
    "mae_all['average'] = mae_all.mean(numeric_only=True, axis=1)\n",
    "label_all_sorted = label_all.loc[mae_all['average'].argsort()[:max_img_nb]]\n",
    "top_pats = label_all_sorted['pat_id'].to_list()\n",
    "\n",
    "data_dt = all_loaders(mypath.data_dir, mypath.label_fpath, args, datasetmode='valid', top_pats=top_pats)\n",
    "dataloader = data_dt['valid']\n",
    "\n",
    "for data in dataloader:\n",
    "    batch_pat_id = data['pat_id'].detach().numpy()\n",
    "    batch_x = data['image']\n",
    "    batch_y = data['label']\n",
    "    batch_ori = data['origin'].detach().numpy()\n",
    "    batch_sp = data['spacing'].detach().numpy()\n",
    "\n",
    "    for pat_id, image, ori, sp, label in zip(batch_pat_id, batch_x, batch_ori, batch_sp, batch_y):\n",
    "        img = image[None].to(device)\n",
    "        print(img.shape)\n",
    "        # attention.run(pat_id, image, ori, sp, label)  # for my own code of RAM\n",
    "        print('Finish pat_id: ', pat_id)\n",
    "print(\"Finish all\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
